**#Challenge Overview
**

This week’s challenge is focused on understanding, exploring, and analyzing solar farm data from Benin, Sierra Leone, and Togo. The challenge aims to evaluate candidates for the 12-week training program in Data Engineering (DE), Financial Analytics (FA), and Machine Learning Engineering (MLE).

Applicants who proceed to the next level by demonstrating sufficient performance in this week's challenge will gain a clear understanding of the discipline, resilience, proactivity, and talent diversity required for the 10 Academy training. Those who do not make it to the limited spots available will gain insight into areas for improvement to prepare for FA, DE, & MLE job positions in the future. Everyone will gain project experience to showcase in their professional profile.

This week is a win-win for everyone. We advise you to put your best effort into completing as many tasks as possible. The number of tasks may seem overwhelming, and you may not have time to build intuition or become comfortable with the new concepts and skills you're exposed to. Please note that building a deeper understanding is not the purpose of this week's project. Moreover, you may have never done or attempted some of the tasks before this training. If you feel confused or overwhelmed, know that it is expected.

The tutors, community managers, and all other teams are here to support you as best as they can. Be proactive in asking questions, provide resources that may help others, and above all, persist!

**Business Objective  **


MoonLight Energy Solutions aims to develop a strategic approach to significantly enhance its operational efficiency and sustainability through targeted solar investments. As an Analytics Engineer at MoonLight Energy Solutions, your task is to perform a quick analysis of an environmental measurement provided by the engineering team and translate your observations into a strategy report. Your analysis should focus on identifying key trends and gaining valuable insights that will support your data-driven case—your recommendation based on statistical analysis and EDA.

In particular, your analysis and recommendation must present a strategy focusing on identifying high-potential regions for solar installation that align with the company's long-term sustainability goals. Your report should provide insights to help realize the overarching objectives of MoonLight Energy Solutions.

**Dataset Overview**  


Solar Radiation Measurement Data
The data for this week's challenge is extracted and aggregated from Solar Radiation Measurement Data. Each row in the data contains values for solar radiation, air temperature, relative humidity, barometric pressure, precipitation, wind speed, wind direction, cleaned and soiled radiance sensors (soiling measurement), and cleaning events.

The structure of the data is as follows:

Timestamp (yyyy-mm-dd hh): Date and time of each observation.

GHI (W/m²): Global Horizontal Irradiance, the total solar radiation received per square meter on a horizontal surface.

DNI (W/m²): Direct Normal Irradiance, the amount of solar radiation received per square meter on a surface perpendicular to the rays of the sun.

DHI (W/m²): Diffuse Horizontal Irradiance, solar radiation received per square meter on a horizontal surface that does not arrive on a direct path from the sun.

ModA (W/m²): Measurements from a module or sensor (A), similar to irradiance.

ModB (W/m²): Measurements from a module or sensor (B), similar to irradiance.

Tamb (°C): Ambient Temperature in degrees Celsius.

RH (%): Relative Humidity as a percentage of moisture in the air.

WS (m/s): Wind Speed in meters per second.

WSgust (m/s): Maximum Wind Gust Speed in meters per second.

WSstdev (m/s): Standard Deviation of Wind Speed, indicating variability.

WD (°N (to east)): Wind Direction in degrees from north.

WDstdev: Standard Deviation of Wind Direction, showing directional variability.

BP (hPa): Barometric Pressure in hectopascals.
Cleaning (1 or 0): Signifying whether cleaning (possibly of the modules or sensors) occurred.
Precipitation (mm/min): Precipitation rate measured in millimeters per minute.
TModA (°C): Temperature of Module A in degrees Celsius.
TModB (°C): Temperature of Module B in degrees Celsius.
Comments: This column is designed for any additional notes.
Week's Topics Covered
Python Programming: Task-specific programming assignments.
GitHub Commands: Continuous committing and repository management.
Data Understanding and Exploration: Applying exploratory data analysis techniques.
CI/CD: Understanding continuous integration and continuous deployment.
Streamlit: Creating a dashboard using Streamlit.
Week 0 Challenge Document
Challenge Overview
This week’s challenge is focused on understanding, exploring, and analyzing solar farm data from Benin, Sierra Leone, and Togo. The challenge aims to evaluate candidates for the 12-week training program in Data Engineering (DE), Financial Analytics (FA), and Machine Learning Engineering (MLE).

Applicants who proceed to the next level by demonstrating sufficient performance in this week's challenge will gain a clear understanding of the discipline, resilience, proactivity, and talent diversity required for the 10 Academy training. Those who do not make it to the limited spots available will gain insight into areas for improvement to prepare for FA, DE, & MLE job positions in the future. Everyone will gain project experience to showcase in their professional profile.

This week is a win-win for everyone. We advise you to put your best effort into completing as many tasks as possible. The number of tasks may seem overwhelming, and you may not have time to build intuition or become comfortable with the new concepts and skills you're exposed to. Please note that building a deeper understanding is not the purpose of this week's project. Moreover, you may have never done or attempted some of the tasks before this training. If you feel confused or overwhelmed, know that it is expected.

The tutors, community managers, and all other teams are here to support you as best as they can. Be proactive in asking questions, provide resources that may help others, and above all, persist!

Business Objective
MoonLight Energy Solutions aims to develop a strategic approach to significantly enhance its operational efficiency and sustainability through targeted solar investments. As an Analytics Engineer at MoonLight Energy Solutions, your task is to perform a quick analysis of an environmental measurement provided by the engineering team and translate your observations into a strategy report. Your analysis should focus on identifying key trends and gaining valuable insights that will support your data-driven case—your recommendation based on statistical analysis and EDA.

In particular, your analysis and recommendation must present a strategy focusing on identifying high-potential regions for solar installation that align with the company's long-term sustainability goals. Your report should provide insights to help realize the overarching objectives of MoonLight Energy Solutions.

Dataset Overview
Solar Radiation Measurement Data
The data for this week's challenge is extracted and aggregated from Solar Radiation Measurement Data. Each row in the data contains values for solar radiation, air temperature, relative humidity, barometric pressure, precipitation, wind speed, wind direction, cleaned and soiled radiance sensors (soiling measurement), and cleaning events.

The structure of the data is as follows:
Timestamp (yyyy-mm-dd hh): Date and time of each observation.
GHI (W/m²): Global Horizontal Irradiance, the total solar radiation received per square meter on a horizontal surface.
DNI (W/m²): Direct Normal Irradiance, the amount of solar radiation received per square meter on a surface perpendicular to the rays of the sun.
DHI (W/m²): Diffuse Horizontal Irradiance, solar radiation received per square meter on a horizontal surface that does not arrive on a direct path from the sun.
ModA (W/m²): Measurements from a module or sensor (A), similar to irradiance.
ModB (W/m²): Measurements from a module or sensor (B), similar to irradiance.
Tamb (°C): Ambient Temperature in degrees Celsius.
RH (%): Relative Humidity as a percentage of moisture in the air.
WS (m/s): Wind Speed in meters per second.
WSgust (m/s): Maximum Wind Gust Speed in meters per second.
WSstdev (m/s): Standard Deviation of Wind Speed, indicating variability.
WD (°N (to east)): Wind Direction in degrees from north.
WDstdev: Standard Deviation of Wind Direction, showing directional variability.
BP (hPa): Barometric Pressure in hectopascals.
Cleaning (1 or 0): Signifying whether cleaning (possibly of the modules or sensors) occurred.
Precipitation (mm/min): Precipitation rate measured in millimeters per minute.
TModA (°C): Temperature of Module A in degrees Celsius.
TModB (°C): Temperature of Module B in degrees Celsius.
Comments: This column is designed for any additional notes.
Week's Topics Covered
Python Programming: Task-specific programming assignments.
GitHub Commands: Continuous committing and repository management.
Data Understanding and Exploration: Applying exploratory data analysis techniques.
CI/CD: Understanding continuous integration and continuous deployment.
Streamlit: Creating a dashboard using Streamlit.
Deliverables and Tasks to be done
Task 1: Git and GitHub
Tasks:

Setting up Python environment
Git version control
CI/CD
Key Performance Indicators (KPIs):

Dev Environment Setup.
Relevant skill in the area demonstrated.
Suggested folder structure:

├── .vscode/
│   └── settings.json
├── .github/
│   └── workflows
│       ├── unittests.yml
├── .gitignore
├── requirements.txt
├── README.md
├── src/
├── notebooks/
│   ├── __init__.py
│   └── README.md
├── tests/
│   ├── __init__.py
└── scripts/
    ├── __init__.py
    └── README.md
Project Planning - EDA & Stats
Tasks:

Data Understanding
Exploratory Data Analysis (EDA)
Statistical thinking
KPIs:

Proactivity to self-learn - sharing references.
EDA techniques to understand data and discover insights.
Demonstrating Stats understanding by using suitable statistical distributions and plots to provide evidence for actionable insights gained from EDA.
Minimum Essential To Do:

Create a GitHub repository that you will be using to host all the code for this week.
Create at least one new branch called "task-1" for your analysis of day 1.
Commit your work at least three times a day with a descriptive commit message.
Perform Exploratory Data Analysis (EDA) analysis on the following:
Summary Statistics: Calculate the mean, median, standard deviation, and other statistical measures for each numeric column to understand data distribution.
Data Quality Check: Look for missing values, outliers, or incorrect entries (e.g., negative values where only positive should exist), especially in columns like GHI, DNI, and DHI, and check for outliers, especially in sensor readings (ModA, ModB) and wind speed data (WS, WSgust).
Time Series Analysis: Plot line graphs or area plots of GHI, DNI, DHI, and Tamb over time to observe patterns by month, trends throughout the day, or anomalies, such as peaks in solar irradiance or temperature fluctuations.
Evaluate the impact of cleaning (using the 'Cleaning' column) on the sensor readings (ModA, ModB) over time.
Correlation Analysis: Use heatmaps or pair plots to visualize the correlations between solar radiation components (GHI, DNI, DHI) and temperature measures (TModA, TModB). Investigate the relationship between wind conditions (WS, WSgust, WD) and solar irradiance using scatter matrices.
Wind Analysis: Use Polar plots to identify trends and significant wind events by showing the distribution of wind speed and direction, along with how variable the wind direction tends to be.
Temperature Analysis: Examine how relative humidity (RH) might influence temperature readings and solar radiation.
Histograms: Create histograms for variables like GHI, DNI, DHI, WS, and temperatures to visualize the frequency distribution of these variables.
Z-Score Analysis: Calculate Z-scores to flag data points that are significantly different from the mean.
Bubble Charts: Explore complex relationships between variables, such as GHI vs. Tamb vs. WS, with bubble size representing an additional variable like RH or BP (Barometric Pressure).
Data Cleaning: Based on the initial analysis, clean the dataset by handling anomalies and missing values, especially in columns like Comments, which appear entirely null.
Bonus Task: Dashboard Development Using Streamlit
Tasks:

Designing and developing a dashboard using Streamlit to visualize data insights.
Integrating Python scripts to fetch and process data dynamically.
Implementing interactive features (e.g., sliders, buttons) to allow users to customize visualizations.
Deploying the Streamlit dashboard to Streamlit Community Cloud.
KPIs:

Dashboard Usability: Ease of use, with intuitive navigation and clear labels.
Interactive Elements: Effective use of Streamlit widgets to enhance user engagement.
Visual Appeal: Clean and professional design that effectively communicates data insights.
Deployment Success: Fully functional deployment, accessible via a public URL.
Suggested Folder Structure:

├── .streamlit
│   └── config.toml
├── .vscode
│   └── settings.json
├── .github
│   └── workflows
│       ├── unittests.yml
├── .gitignore
├── requirements.txt
├── README.md
├── notebooks
│   ├── __init__.py
│   ├── example.ipynb
│   └── README.md
├── tests
│   ├── __init__.py
├── app
│   ├── __init__.py
│   ├── main.py  # main Streamlit application script
│   ├── utils.py  # utility functions for data processing and visualization
└── scripts
    ├── __init__.py
    └── README.md
Minimum Essential To Do:

Merge the necessary branches from task-1 into the main branch using a Pull Request (PR).
Create at least one new branch called "dashboard-dev" for the ongoing development of the dashboard.
Commit your work with a descriptive commit message.
Design and develop the Streamlit dashboard to visualize the dataset with interactive elements.
Document the development process and usage instructions in the README.md file.
Other Considerations
Documentation: Encourage detailed documentation in code and report writing.
Collaboration: Emphasize collaboration through GitHub issues and projects.
Communication: Regular check-ins, Q&A sessions, and a supportive community atmosphere.
Flexibility: Acknowledge potential challenges and encourage proactive communication.
Professionalism: Emphasize work ethics and professional behavior.
Time Management: Stress the importance of punctuality and managing time effectively.**Task 1: Git and GitHub**
Tasks:

Setting up Python environment
Git version control
CI/CD
Key Performance Indicators (KPIs):

Dev Environment Setup.
Relevant skill in the area demonstrated.
Suggested folder structure:

├── .vscode/
│   └── settings.json
├── .github/
│   └── workflows
│       ├── unittests.yml
├── .gitignore
├── requirements.txt
├── README.md
├── src/
├── notebooks/
│   ├── __init__.py
│   └── README.md
├── tests/
│   ├── __init__.py
└── scripts/
    ├── __init__.py
    └── README.md
Project Planning - EDA & Stats
Tasks:

Data Understanding
Exploratory Data Analysis (EDA)
Statistical thinking
KPIs:

Proactivity to self-learn - sharing references.
EDA techniques to understand data and discover insights.
Demonstrating Stats understanding by using suitable statistical distributions and plots to provide evidence for actionable insights gained from EDA.
Minimum Essential To Do:

Create a GitHub repository that you will be using to host all the code for this week.
Create at least one new branch called "task-1" for your analysis of day 1.
Commit your work at least three times a day with a descriptive commit message.
Perform Exploratory Data Analysis (EDA) analysis on the following:
Summary Statistics: Calculate the mean, median, standard deviation, and other statistical measures for each numeric column to understand data distribution.
Data Quality Check: Look for missing values, outliers, or incorrect entries (e.g., negative values where only positive should exist), especially in columns like GHI, DNI, and DHI, and check for outliers, especially in sensor readings (ModA, ModB) and wind speed data (WS, WSgust).
Time Series Analysis: Plot line graphs or area plots of GHI, DNI, DHI, and Tamb over time to observe patterns by month, trends throughout the day, or anomalies, such as peaks in solar irradiance or temperature fluctuations.
Evaluate the impact of cleaning (using the 'Cleaning' column) on the sensor readings (ModA, ModB) over time.
Correlation Analysis: Use heatmaps or pair plots to visualize the correlations between solar radiation components (GHI, DNI, DHI) and temperature measures (TModA, TModB). Investigate the relationship between wind conditions (WS, WSgust, WD) and solar irradiance using scatter matrices.
Wind Analysis: Use Polar plots to identify trends and significant wind events by showing the distribution of wind speed and direction, along with how variable the wind direction tends to be.
Temperature Analysis: Examine how relative humidity (RH) might influence temperature readings and solar radiation.
Histograms: Create histograms for variables like GHI, DNI, DHI, WS, and temperatures to visualize the frequency distribution of these variables.
Z-Score Analysis: Calculate Z-scores to flag data points that are significantly different from the mean.
Bubble Charts: Explore complex relationships between variables, such as GHI vs. Tamb vs. WS, with bubble size representing an additional variable like RH or BP (Barometric Pressure).
Data Cleaning: Based on the initial analysis, clean the dataset by handling anomalies and missing values, especially in columns like Comments, which appear entirely null.
Bonus Task: Dashboard Development Using Streamlit
Tasks:

Designing and developing a dashboard using Streamlit to visualize data insights.
Integrating Python scripts to fetch and process data dynamically.
Implementing interactive features (e.g., sliders, buttons) to allow users to customize visualizations.
Deploying the Streamlit dashboard to Streamlit Community Cloud.
KPIs:

Dashboard Usability: Ease of use, with intuitive navigation and clear labels.
Interactive Elements: Effective use of Streamlit widgets to enhance user engagement.
Visual Appeal: Clean and professional design that effectively communicates data insights.
Deployment Success: Fully functional deployment, accessible via a public URL.
Suggested Folder Structure:

├── .streamlit
│   └── config.toml
├── .vscode
│   └── settings.json
├── .github
│   └── workflows
│       ├── unittests.yml
├── .gitignore
├── requirements.txt
├── README.md
├── notebooks
│   ├── __init__.py
│   ├── example.ipynb
│   └── README.md
├── tests
│   ├── __init__.py
├── app
│   ├── __init__.py
│   ├── main.py  # main Streamlit application script
│   ├── utils.py  # utility functions for data processing and visualization
└── scripts
    ├── __init__.py
    └── README.md
Minimum Essential To Do:

Merge the necessary branches from task-1 into the main branch using a Pull Request (PR).
Create at least one new branch called "dashboard-dev" for the ongoing development of the dashboard.
Commit your work with a descriptive commit message.
Design and develop the Streamlit dashboard to visualize the dataset with interactive elements.
Document the development process and usage instructions in the README.md file.
Other Considerations
Documentation: Encourage detailed documentation in code and report writing.
Collaboration: Emphasize collaboration through GitHub issues and projects.
Communication: Regular check-ins, Q&A sessions, and a supportive community atmosphere.
Flexibility: Acknowledge potential challenges and encourage proactive communication.
Professionalism: Emphasize work ethics and professional behavior.
Time Management: Stress the importance of punctuality and managing time effectively.
